{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yZpVDMOZoh0F"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ClJBfzSpUZA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n"
          ]
        }
      ],
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eajHTK-sqXG9"
      },
      "outputs": [],
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fBmCKTKbqwZs"
      },
      "outputs": [],
      "source": [
        "text = text[300000:800000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x99sYMKItCKW"
      },
      "outputs": [],
      "source": [
        "characters = sorted(set(text))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g1m-O3jBxFmz"
      },
      "outputs": [],
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_char = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7hDMdGIHxuqn"
      },
      "outputs": [],
      "source": [
        "# From here next 4 cell are not needed 'afte training' the model and saving it\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i+SEQ_LENGTH])\n",
        "    next_char.append(text[i+SEQ_LENGTH])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O-SyZCEv7XB2"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vnsx6q4AZRl",
        "outputId": "ebc380df-8f6b-4da9-bec3-119ae45108e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ARSALAN\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIxsv4ht_lbg",
        "outputId": "00d61259-9a1f-4644-b454-63bec8306603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m 18/651\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 188ms/step - loss: 3.3950"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.01))\n",
        "\n",
        "model.fit(x,y, batch_size=256, epochs=4)\n",
        "\n",
        "# After training the model, the model is saved in next step so we don't have to train it again and again\n",
        "# and we will be using that file(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oMwuN7EaAwK5"
      },
      "outputs": [],
      "source": [
        "model.save('textgenerator.keras') # Change the file name to include .keras extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5eMxpyv8BKm2"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g9UKMuaIDBck"
      },
      "outputs": [],
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgr_ymfIDXfu",
        "outputId": "03486478-1f6a-4ba4-9147-b333845e13e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " nay, the valley,\n",
            "the pretty dimples of the will the world.\n",
            "\n",
            "romeo:\n",
            "and i should the world the streather and stready,\n",
            "the brother and the will and the some his stand\n",
            "the cread and streather and the love and the soul,\n",
            "and the soul should the world the son and streath,\n",
            "the soul should the world the warter then shall the world.\n",
            "\n",
            "king richard\n",
            "ose thy lips.\n",
            "\n",
            "king henry vi:\n",
            "i prithee, then the lord: the sacress of seeks\n",
            "in the king a more and the crawner from the king.\n",
            "\n",
            "king richard ii:\n",
            "i have the parton the warward but are surpess.\n",
            "\n",
            "cloffory:\n",
            "i should my son the were the warter of the world.\n",
            "\n",
            "cloffory:\n",
            "i should the callace of the world should her so sull.\n",
            "but i say the down tha\n",
            "and, that was wont to conquer others,\n",
            "hath the shall be the renting to merch.\n",
            "\n",
            "york:\n",
            "i shall be are my earth the may your lord.\n",
            "\n",
            "romeo:\n",
            "the forth the heavens consented the creath.\n",
            "\n",
            "gloucester:\n",
            "and the mistring his gards un all and here shall will.\n",
            "\n",
            "mercutio:\n",
            "no lord, and but the ponton that the warth,\n",
            "there the rest thee fair word and spe\n",
            "the heads of too fast growing sprays,\n",
            "the last made an and surine and man's flound,\n",
            "and this the beling some the worse, when i do her,\n",
            "who hath then well fearter way the great\n",
            "from a forling mace his lords, my conserment.\n",
            "\n",
            "clifford:\n",
            "i am a hard, there longer of with our blehds.\n",
            "\n",
            "mercutio:\n",
            "any shows death, she would well ners me are for,\n",
            "t\n",
            "y wrath, say so;\n",
            "the bastard brains with that us we bready,\n",
            "to have leave of the wing all me should.\n",
            "\n",
            "nurse:\n",
            "yon, thou wilh the callard, take is my lord.\n",
            "\n",
            "juliet:\n",
            "i will leave he stand the childs world weep.\n",
            "\n",
            "nurse:\n",
            "yes back my king many nuth the whild the king,\n",
            "or should me an thou will a sear in more.\n",
            "thou wilt me! do thy live.\n",
            "\n",
            "romeo:\n",
            "\n",
            "rth,\n",
            "and, being anger'd, puffs away from the roor'd.\n",
            "\n",
            "king richard ii:\n",
            "now, what so in steer full, he, whon his sack,\n",
            "to shrould the worms call in my wit not,\n",
            "sir shall this forture a shall with his bend;\n",
            "be thou were here deadero, breakene, lord:\n",
            "what that shild the sid, and stay unfey and think,\n",
            "the herise unfellion fight lore and with \n"
          ]
        }
      ],
      "source": [
        "print(generate_text(300, 0.2))\n",
        "print(generate_text(300, 0.4))\n",
        "print(generate_text(300, 0.5))\n",
        "print(generate_text(300, 0.6))\n",
        "print(generate_text(300, 0.7))\n",
        "print(generate_text(300, 0.8))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
